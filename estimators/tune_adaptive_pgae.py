#!/usr/bin/env python3
"""
Adaptive PGAEè°ƒå‚è„šæœ¬
Adaptive PGAE batch_size parameter tuning tool
ä¼˜åŒ–batch_sizeå‚æ•°ä»¥æå‡Adaptive PGAEæ€§èƒ½
"""

import numpy as np
import pandas as pd
import time
import logging
import json
from typing import Dict, List
from tqdm import tqdm
from itertools import product

from adaptive_pgae_estimator import AdaptivePGAEEstimator
from utils import summary_results

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_adaptive_design_combinations(df: pd.DataFrame, batch_sizes: List[int], 
                                     gamma_values: List[float], design_update_freqs: List[int],
                                     warmup_batches_list: List[int], target_config: Dict) -> Dict:
    """
    æµ‹è¯•Adaptive PGAEçš„æ”¹è¿›è®¾è®¡å‚æ•°ç»„åˆ
    
    Args:
        df: æ•°æ®DataFrame
        batch_sizes: è¦æµ‹è¯•çš„batch_sizeåˆ—è¡¨
        gamma_values: è¦æµ‹è¯•çš„gammaå€¼åˆ—è¡¨
        design_update_freqs: è¦æµ‹è¯•çš„è®¾è®¡æ›´æ–°é¢‘ç‡åˆ—è¡¨
        warmup_batches_list: è¦æµ‹è¯•çš„é¢„çƒ­æ‰¹æ¬¡æ•°åˆ—è¡¨
        target_config: ç›®æ ‡é…ç½®å­—å…¸
    
    Returns:
        è°ƒå‚ç»“æœå­—å…¸
    """
    total_combinations = len(batch_sizes) * len(gamma_values) * len(design_update_freqs) * len(warmup_batches_list)
    logger.info(f"æµ‹è¯•Adaptive PGAEæ”¹è¿›è®¾è®¡å‚æ•°ï¼Œæ€»å…±{total_combinations}ä¸ªç»„åˆ")
    logger.info(f"batch_sizes: {batch_sizes}")
    logger.info(f"gamma_values: {gamma_values}")
    logger.info(f"design_update_freqs: {design_update_freqs}")
    logger.info(f"warmup_batches: {warmup_batches_list}")
    
    results = {}
    
    # ç½‘æ ¼æœç´¢æ‰€æœ‰å‚æ•°ç»„åˆ
    for batch_size in tqdm(batch_sizes, desc="Testing batch sizes"):
        for gamma in gamma_values:
            for update_freq in design_update_freqs:
                for warmup in warmup_batches_list:
                    combo_name = f'bs_{batch_size}_g_{gamma}_uf_{update_freq}_wb_{warmup}'
                    
                    logger.info(f"\næµ‹è¯•ç»„åˆ: batch_size={batch_size}, gamma={gamma}, "
                               f"update_freq={update_freq}, warmup={warmup}")
        
                    try:
                        result = run_single_adaptive_design_test(
                            df, target_config, batch_size, gamma, update_freq, warmup, 
                            n_experiments=20  # å‡å°‘å®éªŒæ¬¡æ•°ä»¥åŠ é€Ÿæµ‹è¯•
                        )
                        
                        results[combo_name] = {
                            'batch_size': batch_size,
                            'gamma': gamma,
                            'design_update_freq': update_freq,
                            'warmup_batches': warmup,
                            'mse': result['mse'],
                            'bias': result['bias'],
                            'variance': result['variance'],
                            'coverage_rate': result['coverage_rate'],
                            'avg_ci_length': result['avg_ci_length'],
                            'execution_time': result['execution_time'],
                            'true_value': result['true_value']
                        }
                        
                        logger.info(f"  MSE: {result['mse']:.6f}, "
                                   f"è¦†ç›–ç‡: {result['coverage_rate']:.3f}, "
                                   f"æ—¶é—´: {result['execution_time']:.1f}s")
                                   
                    except Exception as e:
                        logger.error(f"  ç»„åˆ {combo_name} å¤±è´¥: {e}")
                        results[combo_name] = {
                            'batch_size': batch_size,
                            'gamma': gamma,
                            'design_update_freq': update_freq,
                            'warmup_batches': warmup,
                            'error': str(e)
                        }
    
    return results

def run_single_adaptive_design_test(df: pd.DataFrame, target_config: Dict, 
                                    batch_size: int, gamma: float, 
                                    design_update_freq: int, warmup_batches: int,
                                    n_experiments: int = 20) -> Dict:
    """
    è¿è¡Œå•ä¸ªAdaptive PGAEæ”¹è¿›è®¾è®¡å‚æ•°ç»„åˆçš„æµ‹è¯•
    
    Args:
        df: æ•°æ®DataFrame
        target_config: ç›®æ ‡é…ç½®
        batch_size: batchå¤§å°
        gamma: gammaå‚æ•°
        design_update_freq: è®¾è®¡æ›´æ–°é¢‘ç‡
        warmup_batches: é¢„çƒ­æ‰¹æ¬¡æ•°
        n_experiments: å®éªŒæ¬¡æ•°
    
    Returns:
        å®éªŒç»“æœå­—å…¸
    """
    # åˆ›å»ºæ”¹è¿›ç‰ˆä¼°è®¡å™¨
    estimator = AdaptivePGAEEstimator(
        X=target_config['X'],
        F=target_config['F'],
        Y=target_config['Y'],
        gamma=gamma,
        batch_size=batch_size,
        design_update_freq=design_update_freq,
        warmup_batches=warmup_batches
    )
    
    # è¿è¡Œå®éªŒ
    start_time = time.time()
    experiment_results = estimator.run_experiments(
        df,
        n_experiments=n_experiments,
        n_true_labels=500,
        alpha=0.9,
        seed=42,
        use_concurrent=True,
        max_workers=10  # é™åˆ¶workeræ•°é‡ä»¥èŠ‚çœå†…å­˜
    )
    end_time = time.time()
    
    return {
        'mse': experiment_results['mse'],
        'bias': experiment_results['bias'],
        'variance': experiment_results['variance'],
        'coverage_rate': experiment_results['coverage_rate'],
        'avg_ci_length': experiment_results['avg_ci_length'],
        'execution_time': end_time - start_time,
        'true_value': experiment_results['true_value']
    }

def run_single_batch_gamma_test(df: pd.DataFrame, target_config: Dict, 
                                batch_size: int, gamma: float, 
                                n_experiments: int = 30) -> Dict:
    """
    è¿è¡Œå•ä¸ªbatch_sizeå’Œgammaå€¼ç»„åˆçš„æµ‹è¯•
    
    Args:
        df: æ•°æ®DataFrame
        target_config: ç›®æ ‡é…ç½®
        batch_size: batchå¤§å°
        gamma: gammaå‚æ•°
        n_experiments: å®éªŒæ¬¡æ•°
    
    Returns:
        å®éªŒç»“æœå­—å…¸
    """
    # åˆ›å»ºä¼°è®¡å™¨
    estimator = AdaptivePGAEEstimator(
        X=target_config['X'],
        F=target_config['F'],
        Y=target_config['Y'],
        gamma=gamma,
        batch_size=batch_size
    )
    
    # è¿è¡Œå®éªŒ
    start_time = time.time()
    experiment_results = estimator.run_experiments(
        df,
        n_experiments=n_experiments,
        n_true_labels=500,
        alpha=0.9,
        seed=42,
        use_concurrent=True,
        max_workers=10  # é™åˆ¶workeræ•°é‡ä»¥èŠ‚çœå†…å­˜
    )
    end_time = time.time()
    
    return {
        'mse': experiment_results['mse'],
        'bias': experiment_results['bias'],
        'variance': experiment_results['variance'],
        'coverage_rate': experiment_results['coverage_rate'],
        'avg_ci_length': experiment_results['avg_ci_length'],
        'execution_time': end_time - start_time,
        'true_value': experiment_results['true_value']
    }

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python tune_adaptive_pgae.py <data_file>")
        print("  python tune_adaptive_pgae.py data/NPORS_2024_for_public_release_with_LLM_prediction.csv")
        return
    
    data_file = sys.argv[1]
    logger.info(f"åŠ è½½æ•°æ®: {data_file}")
    df = pd.read_csv(data_file)
    
    # ç›®æ ‡é…ç½®
    TARGET_CONFIGS = {
        'ECON1MOD': {
            'X': ['EDUCATION'],
            'F': 'ECON1MOD_LLM',
            'Y': 'ECON1MOD',
        },
        'UNITY': {
            'X': ['EDUCATION'],
            'F': 'UNITY_LLM', 
            'Y': 'UNITY',
        },
        'GPT1': {
            'X': ['EDUCATION'],
            'F': 'GPT1_LLM',
            'Y': 'GPT1',
        }
    }
    
    # å®šä¹‰è¦æµ‹è¯•çš„æ”¹è¿›è®¾è®¡å‚æ•° - å›ºå®šgamma=0.5
    batch_sizes = [25, 50, 100, 150, 250]  # ç²¾é€‰batch_sizeèŒƒå›´
    gamma_values = [0.5]  # å›ºå®šgamma=0.5
    design_update_freqs = [1, 2, 3]  # è®¾è®¡æ›´æ–°é¢‘ç‡ï¼šæ¯1,2,3æ‰¹æ›´æ–°ä¸€æ¬¡
    warmup_batches_list = [0, 2, 5]  # é¢„çƒ­æ‰¹æ¬¡ï¼š0,2,5æ‰¹é¢„çƒ­
    
    # é€‰æ‹©ç›®æ ‡ä»»åŠ¡ (é»˜è®¤ECON1MOD)
    target = 'ECON1MOD'
    target_config = TARGET_CONFIGS[target]
    
    logger.info(f"ç›®æ ‡ä»»åŠ¡: {target}")
    logger.info(f"é…ç½®: {target_config}")
    logger.info("æµ‹è¯•Adaptive PGAEæ”¹è¿›è®¾è®¡ï¼šæ›´æ–°é¢‘ç‡æ§åˆ¶ + é¢„çƒ­æœºåˆ¶ (å›ºå®šgamma=0.5)")
    
    total_combinations = len(batch_sizes) * len(gamma_values) * len(design_update_freqs) * len(warmup_batches_list)
    logger.info(f"å°†æµ‹è¯•{total_combinations}ä¸ªå‚æ•°ç»„åˆ (3Ã—1Ã—3Ã—3=27)")
    
    # è¿è¡Œæ”¹è¿›è®¾è®¡å‚æ•°æµ‹è¯•
    results = test_adaptive_design_combinations(
        df, batch_sizes, gamma_values, design_update_freqs, warmup_batches_list, target_config
    )
    
    # åˆ†æç»“æœå¹¶è¾“å‡º
    print("\n" + "="*100)
    print("ADAPTIVE PGAE æ”¹è¿›è®¾è®¡å‚æ•°è°ƒä¼˜ç»“æœ")
    print("="*100)
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_results = {k: v for k, v in results.items() if 'error' not in v}
    
    if not valid_results:
        print("âŒ æ‰€æœ‰å‚æ•°ç»„åˆæµ‹è¯•å‡å¤±è´¥")
        return
    
    # æŒ‰MSEæ’åºæ˜¾ç¤ºç»“æœ
    sorted_results = sorted(valid_results.items(), key=lambda x: x[1]['mse'])
    
    print(f"{'Batch':<6} {'Update':<7} {'Warmup':<7} {'MSE':<12} {'Coverage':<10} {'Time(s)':<8}")
    print("-" * 70)
    
    for combo_name, combo_data in sorted_results[:15]:  # æ˜¾ç¤ºå‰15ä¸ªæœ€ä½³ç»“æœï¼ˆæ›´å¤šç»“æœï¼‰
        batch_size = combo_data['batch_size']
        update_freq = combo_data['design_update_freq']
        warmup = combo_data['warmup_batches']
        mse = combo_data['mse']
        coverage = combo_data['coverage_rate']
        time_taken = combo_data['execution_time']
        
        print(f"{batch_size:<6} {update_freq:<7} {warmup:<7} {mse:<12.6f} {coverage:<10.3f} {time_taken:<8.1f}")
    
    # æ‰¾åˆ°æœ€ä½³å‚æ•°ç»„åˆ
    best_combo_name, best_combo_data = sorted_results[0]
    best_batch_size = best_combo_data['batch_size']
    best_update_freq = best_combo_data['design_update_freq']
    best_warmup = best_combo_data['warmup_batches']
    best_mse = best_combo_data['mse']
    best_coverage = best_combo_data['coverage_rate']
    
    print("\n" + "="*70)
    print(f"ğŸ† æœ€ä½³æ”¹è¿›è®¾è®¡ç»„åˆ (gamma=0.5):")
    print(f"   batch_size={best_batch_size}")
    print(f"   è®¾è®¡æ›´æ–°é¢‘ç‡={best_update_freq}æ‰¹, é¢„çƒ­æ‰¹æ¬¡={best_warmup}")
    print(f"   MSE: {best_mse:.6f}")
    print(f"   è¦†ç›–ç‡: {best_coverage:.3f}")
    print(f"   åŸå§‹baseline: MSE â‰ˆ 0.004201")
    
    # è®¡ç®—æ”¹å–„ç¨‹åº¦
    current_mse = 0.004201  # å½“å‰Adaptive PGAEçš„MSE
    improvement = ((current_mse - best_mse) / current_mse) * 100
    
    print(f"\nğŸ“ åº”ç”¨å»ºè®®:")
    print(f"   æ›´æ–°compare_estimators.pyä¸­çš„Adaptive PGAEå‚æ•°:")
    print(f"   - gamma=0.5 (å›ºå®š)")
    print(f"   - batch_size={best_batch_size}")  
    print(f"   - design_update_freq={best_update_freq} (æ¯{best_update_freq}æ‰¹æ›´æ–°ä¸€æ¬¡è®¾è®¡)")
    print(f"   - warmup_batches={best_warmup} (å‰{best_warmup}æ‰¹ä½¿ç”¨å›ºå®šè®¾è®¡)")
    print(f"   é¢„æœŸMSEæ”¹å–„: {improvement:.1f}% (ä» {current_mse:.6f} é™åˆ° {best_mse:.6f})")
    
    # å¦‚æœæ”¹å–„æ˜¾è‘—ï¼Œç»™å‡ºæ›´å…·ä½“çš„å»ºè®®
    if improvement > 20:
        print(f"   âœ… æ˜¾è‘—æ”¹å–„ï¼æ”¹è¿›è®¾è®¡å¤§å¹…æå‡Adaptive PGAEæ€§èƒ½")
    elif improvement > 10:
        print(f"   âœ… ä¸­ç­‰æ”¹å–„ï¼Œè®¾è®¡ä¼˜åŒ–å¸¦æ¥æ˜æ˜¾æå‡")  
    else:
        print(f"   âš ï¸  æ”¹å–„æœ‰é™ï¼Œä½†è®¾è®¡æ›´ç¨³å®šï¼ˆå‡å°‘æ³¢åŠ¨ï¼‰")
    
    # ä¿å­˜ç»“æœ
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_file = f'adaptive_pgae_design_tuning_{target.lower()}_{timestamp}.json'
    
    # æ·»åŠ æ€»ç»“åˆ°ç»“æœä¸­
    results['summary'] = {
        'target': target,
        'fixed_gamma': 0.5,  # å›ºå®šgammaå€¼
        'best_batch_size': best_batch_size,
        'best_design_update_freq': best_update_freq,
        'best_warmup_batches': best_warmup,
        'best_mse': best_mse,
        'best_coverage': best_coverage,
        'improvement_percent': improvement,
        'tested_parameters': {
            'batch_sizes': batch_sizes,
            'gamma_values': gamma_values,
            'design_update_freqs': design_update_freqs,
            'warmup_batches_list': warmup_batches_list
        },
        'total_combinations': len(batch_sizes) * len(gamma_values) * len(design_update_freqs) * len(warmup_batches_list),
        'successful_tests': len(valid_results)
    }
    
    # è½¬æ¢numpyç±»å‹ä¸ºpythonåŸç”Ÿç±»å‹ (å‚è€ƒtune_internal_parameters.py)
    def convert_numpy(obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {key: convert_numpy(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy(item) for item in obj]
        return obj
    
    with open(output_file, 'w') as f:
        json.dump(convert_numpy(results), f, indent=2)
    
    print(f"\nâœ… Adaptive PGAEæ”¹è¿›è®¾è®¡è°ƒå‚å®Œæˆ!")
    print(f"æµ‹è¯•äº†{len(valid_results)}ä¸ªæœ‰æ•ˆå‚æ•°ç»„åˆ")
    print(f"ç»“æœæ–‡ä»¶: {output_file}")

if __name__ == "__main__":
    main()
