#!/usr/bin/env python3
"""
Adaptive PGAE (Prediction-Guided Active Experiments) Estimator
è‡ªé€‚åº”é¢„æµ‹å¼•å¯¼ä¸»åŠ¨å®éªŒä¼°è®¡å™¨
"""

import numpy as np
import pandas as pd
import time
import logging
from tqdm import tqdm
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp
import gc
from utils import (
    get_PGAE_design, rejection_sample, PGAE_est_ci,
    overwrite_merge, summary_results, validate_data
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AdaptivePGAEEstimator:
    """è‡ªé€‚åº”PGAEä¼°è®¡å™¨ç±»"""
    
    def __init__(self, X: List[str], F: str, Y: str, gamma: float = 0.5, batch_size: int = 100,
                 design_update_freq: int = 1, warmup_batches: int = 0):
        """
        åˆå§‹åŒ–è‡ªé€‚åº”PGAEä¼°è®¡å™¨
        
        Args:
            X: åå˜é‡åˆ—ååˆ—è¡¨
            F: é¢„æµ‹åˆ—å
            Y: çœŸå®æ ‡ç­¾åˆ—å
            gamma: PGAEå‚æ•°ï¼Œæ§åˆ¶å®éªŒæ¦‚ç‡çš„æƒé‡
            batch_size: æ¯æ‰¹æ¬¡çš„æ ·æœ¬æ•°é‡
            design_update_freq: è®¾è®¡æ›´æ–°é¢‘ç‡ï¼ˆæ¯å‡ ä¸ªbatchæ›´æ–°ä¸€æ¬¡è®¾è®¡ï¼Œé»˜è®¤1ä¸ºæ¯æ‰¹éƒ½æ›´æ–°ï¼‰
            warmup_batches: é¢„çƒ­æ‰¹æ¬¡æ•°ï¼ˆå‰å‡ æ‰¹å›ºå®šä½¿ç”¨åˆå§‹è®¾è®¡ï¼Œä¸è¿›è¡Œè‡ªé€‚åº”æ›´æ–°ï¼‰
        """
        self.X = X
        self.F = F
        self.Y = Y
        self.gamma = gamma
        self.batch_size = batch_size
        self.design_update_freq = design_update_freq
        self.warmup_batches = warmup_batches
        
        logger.info(f"è‡ªé€‚åº”PGAEä¼°è®¡å™¨åˆå§‹åŒ–: X={X}, F={F}, Y={Y}, gamma={gamma}, batch_size={batch_size}")
        if design_update_freq > 1:
            logger.info(f"  è®¾è®¡æ›´æ–°é¢‘ç‡: æ¯{design_update_freq}æ‰¹æ›´æ–°ä¸€æ¬¡ï¼ˆå‡å°‘æ³¢åŠ¨ä¸å¼€é”€ï¼‰")
        if warmup_batches > 0:
            logger.info(f"  é¢„çƒ­æ‰¹æ¬¡æ•°: å‰{warmup_batches}æ‰¹ä½¿ç”¨åˆå§‹è®¾è®¡ï¼ˆæå‡åˆæœŸç¨³å®šæ€§ï¼‰")
    
    def prepare_initial_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å‡†å¤‡åˆå§‹æ•°æ®
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        # éªŒè¯æ•°æ®
        required_columns = self.X + [self.F, self.Y]
        if not validate_data(df, required_columns):
            raise ValueError("Data validation failed")
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        df_clean = df[required_columns].copy()
        df_clean = df_clean[df_clean[required_columns].lt(10).all(axis=1)]
        
        logger.info(f"æ•°æ®æ¸…ç†åæ ·æœ¬æ•°: {len(df_clean)}")
        
        # è®¡ç®—çœŸå®PMF
        group_stats = df_clean.groupby(self.X).agg(
            cnt=(self.F, 'count')
        ).reset_index()
        
        group_stats['true_pmf'] = group_stats['cnt'] / group_stats['cnt'].sum()
        df_clean = df_clean.merge(group_stats, on=self.X, how='left')
        
        return df_clean
    
    def run_single_adaptive_experiment(self, df: pd.DataFrame, n_true_labels: int = 500, 
                                     alpha: float = 0.9, seed: Optional[int] = None) -> Tuple[float, float, float]:
        """
        è¿è¡Œå•æ¬¡è‡ªé€‚åº”PGAEå®éªŒ
        
        Args:
            df: å‡†å¤‡å¥½çš„æ•°æ®æ¡†
            n_true_labels: ç›®æ ‡çœŸå®æ ‡ç­¾æ•°é‡
            alpha: ç½®ä¿¡æ°´å¹³
            seed: éšæœºç§å­
            
        Returns:
            (ä¼°è®¡å€¼, ç½®ä¿¡åŒºé—´ä¸‹ç•Œ, ç½®ä¿¡åŒºé—´ä¸Šç•Œ)
        """
        if seed is not None:
            np.random.seed(seed)
        
        df_work = df.copy()
        df_work['true_label'] = 0
        
        cnt_true = 0
        PGAE_df = pd.DataFrame()
        
        # åˆå§‹åŒ–è®¾è®¡å‚æ•°
        initial_design = pd.DataFrame()
        for x_val in df_work[self.X].drop_duplicates().values:
            if len(self.X) == 1:
                x_val = [x_val]
            row = dict(zip(self.X, x_val))
            
            # å®‰å…¨è·å–sample_pmf
            if len(self.X) == 1:
                mask = df_work[self.X[0]] == x_val[0]
            else:
                mask = df_work[self.X].eq(x_val).all(axis=1)
                
            matched_rows = df_work.loc[mask, 'true_pmf']
            sample_pmf_val = matched_rows.iloc[0] if len(matched_rows) > 0 else 1.0
            
            row.update({
                'accept_prob': 1.0,
                'exp_prob': 1.0,
                'sample_pmf': sample_pmf_val
            })
            initial_design = pd.concat([initial_design, pd.DataFrame([row])], ignore_index=True)
        
        df_work = overwrite_merge(df_work, initial_design, on=self.X, how='left')
        
        # è‡ªé€‚åº”é‡‡æ ·å¾ªç¯
        batch_count = 0
        logger.info(f"å¼€å§‹è‡ªé€‚åº”é‡‡æ ·ï¼šç›®æ ‡{n_true_labels}ä¸ªæ ‡ç­¾ï¼Œæ‰¹æ¬¡å¤§å°{self.batch_size}")
        logger.info(f"é¢„çƒ­è®¾ç½®ï¼šå‰{self.warmup_batches}æ‰¹å›ºå®šè®¾è®¡ï¼Œæ¯{self.design_update_freq}æ‰¹æ›´æ–°ä¸€æ¬¡")
        
        while cnt_true < n_true_labels:
            batch_count += 1
            
            # é‡‡æ ·ä¸€ä¸ªæ‰¹æ¬¡
            sampled_df = rejection_sample(df_work, df_work.columns, 'accept_prob', 
                                        n_samples=self.batch_size)
            
            # æ ¹æ®å®éªŒæ¦‚ç‡å†³å®šæ˜¯å¦æ ‡è®°
            u = np.random.uniform(0, 1, size=len(sampled_df))
            sampled_df['true_label'] = (u < sampled_df['exp_prob']).astype(int)
            
            batch_true_labels = sampled_df['true_label'].sum()
            cnt_true += batch_true_labels
            PGAE_df = pd.concat([PGAE_df, sampled_df], ignore_index=True)
            
            logger.info(f"ç¬¬{batch_count}æ‰¹ï¼šè·å¾—{batch_true_labels}ä¸ªæ ‡ç­¾ï¼Œæ€»è®¡{cnt_true}/{n_true_labels}")
            
            # è®¾è®¡æ›´æ–°é€»è¾‘ï¼šè€ƒè™‘é¢„çƒ­æœŸå’Œæ›´æ–°é¢‘ç‡
            should_update_design = (
                len(PGAE_df[PGAE_df['true_label'] == 1]) > 0 and  # æœ‰æ ‡è®°æ•°æ®
                batch_count > self.warmup_batches and  # è¿‡äº†é¢„çƒ­æœŸ
                batch_count % self.design_update_freq == 0  # åˆ°äº†æ›´æ–°é¢‘ç‡
            )
            
            if should_update_design:
                try:
                    updated_design = get_PGAE_design(PGAE_df, self.X, self.F, self.Y, self.gamma)
                    df_work = overwrite_merge(df_work, updated_design, on=self.X, how='left')
                    logger.info(f"ç¬¬{batch_count}æ‰¹ï¼šâœ…æ›´æ–°è®¾è®¡å‚æ•°")
                except Exception as e:
                    # å¦‚æœè®¾è®¡æ›´æ–°å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰è®¾è®¡
                    logger.warning(f"ç¬¬{batch_count}æ‰¹è®¾è®¡æ›´æ–°å¤±è´¥: {e}")
            elif batch_count <= self.warmup_batches:
                logger.info(f"ç¬¬{batch_count}æ‰¹ï¼šğŸ”¥é¢„çƒ­æœŸï¼Œä½¿ç”¨å›ºå®šè®¾è®¡")
            else:
                logger.info(f"ç¬¬{batch_count}æ‰¹ï¼šâ­ï¸è·³è¿‡è®¾è®¡æ›´æ–°ï¼ˆé¢‘ç‡æ§åˆ¶ï¼‰")
        
        # æˆªæ–­åˆ°ç›®æ ‡æ ‡ç­¾æ•°é‡
        if cnt_true > n_true_labels:
            PGAE_df['cum_sum'] = PGAE_df['true_label'].cumsum()
            cutoff_mask = PGAE_df['cum_sum'] <= n_true_labels
            PGAE_df = PGAE_df[cutoff_mask]
        
        # è®¡ç®—ä¼°è®¡å€¼å’Œç½®ä¿¡åŒºé—´ - é‡‡æ ·å®Œæˆåä½¿ç”¨regular PGAEçš„CVæ–¹æ³•
        tau, l_ci, h_ci = PGAE_est_ci(PGAE_df, self.X, self.F, self.Y, alpha=alpha, K=3)
        
        return tau, l_ci, h_ci
    
    def run_experiments(self, df: pd.DataFrame, n_experiments: int = 1000, 
                       n_true_labels: int = 500, alpha: float = 0.9, 
                       seed: Optional[int] = None, use_concurrent: bool = True,
                       max_workers: Optional[int] = 10) -> Dict:
        """
        è¿è¡Œå¤šæ¬¡è‡ªé€‚åº”PGAEå®éªŒ
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            n_experiments: å®éªŒæ¬¡æ•°
            n_true_labels: æ¯æ¬¡å®éªŒçš„çœŸå®æ ‡ç­¾æ•°é‡
            alpha: ç½®ä¿¡æ°´å¹³
            seed: éšæœºç§å­
            use_concurrent: æ˜¯å¦ä½¿ç”¨å¹¶å‘æ‰§è¡Œ
            max_workers: æœ€å¤§å¹¶å‘workeræ•°é‡
            
        Returns:
            å®éªŒç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹è‡ªé€‚åº”PGAEå®éªŒ: {n_experiments}æ¬¡å®éªŒ, æ¯æ¬¡{n_true_labels}ä¸ªæ ‡ç­¾")
        if use_concurrent:
            logger.info("ä½¿ç”¨å¹¶å‘æ‰§è¡Œæ¨¡å¼")
        
        # å‡†å¤‡æ•°æ®
        df_prepared = self.prepare_initial_data(df)
        true_value = df_prepared[self.Y].mean()
        
        logger.info(f"çœŸå®ç›®æ ‡å€¼: {true_value:.6f}")
        
        # è®¾ç½®éšæœºç§å­
        if seed is not None:
            np.random.seed(seed)
        
        # è¿è¡Œå®éªŒ
        start_time = time.time()
        
        if use_concurrent:
            # å¹¶å‘æ‰§è¡Œ
            tau_results, l_ci_results, h_ci_results = self._run_concurrent_experiments(
                df_prepared, n_experiments, n_true_labels, alpha, seed, max_workers
            )
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            tau_results, l_ci_results, h_ci_results = self._run_sequential_experiments(
                df_prepared, n_experiments, n_true_labels, alpha, seed
            )
        
        end_time = time.time()
        
        # æ±‡æ€»ç»“æœ
        results = summary_results(tau_results, l_ci_results, h_ci_results, 
                                true_value, "Adaptive PGAE")
        
        results.update({
            'tau_estimates': tau_results,
            'l_ci': l_ci_results,
            'h_ci': h_ci_results,
            'true_value': true_value,
            'execution_time': end_time - start_time,
            'parameters': {
                'X': self.X,
                'F': self.F,
                'Y': self.Y,
                'gamma': self.gamma,
                'batch_size': self.batch_size,
                'n_experiments': n_experiments,
                'n_true_labels': n_true_labels,
                'alpha': alpha
            }
        })
        
        logger.info(f"è‡ªé€‚åº”PGAEå®éªŒå®Œæˆï¼Œè€—æ—¶: {results['execution_time']:.2f}ç§’")
        
        return results
    
    def _run_sequential_experiments(self, df_prepared: pd.DataFrame, n_experiments: int,
                                  n_true_labels: int, alpha: float, seed: Optional[int]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """ä¸²è¡Œæ‰§è¡Œå®éªŒ"""
        tau_results = np.zeros(n_experiments)
        l_ci_results = np.zeros(n_experiments)
        h_ci_results = np.zeros(n_experiments)
        
        for i in tqdm(range(n_experiments), desc="è‡ªé€‚åº”PGAEå®éªŒè¿›è¡Œä¸­"):
            exp_seed = None if seed is None else seed + i
            tau, l_ci, h_ci = self.run_single_adaptive_experiment(
                df_prepared, n_true_labels, alpha, exp_seed
            )
            
            tau_results[i] = tau
            l_ci_results[i] = l_ci
            h_ci_results[i] = h_ci
            
        return tau_results, l_ci_results, h_ci_results
    
    def _run_concurrent_experiments(self, df_prepared: pd.DataFrame, n_experiments: int,
                                  n_true_labels: int, alpha: float, seed: Optional[int], 
                                  max_workers: Optional[int]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """å¹¶å‘æ‰§è¡Œå®éªŒ"""
        if max_workers is None:
            max_workers = min(mp.cpu_count(), n_experiments, 10)  # é»˜è®¤é™åˆ¶ä¸º10
        
        logger.info(f"ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘worker")
        
        # å‡†å¤‡ä»»åŠ¡å‚æ•°
        task_args = []
        for i in range(n_experiments):
            exp_seed = None if seed is None else seed + i
            task_args.append((df_prepared, self.X, self.F, self.Y, self.gamma, self.batch_size,
                              self.design_update_freq, self.warmup_batches,
                              n_true_labels, alpha, exp_seed))
        
        # åˆå§‹åŒ–ç»“æœæ•°ç»„
        tau_results = np.zeros(n_experiments)
        l_ci_results = np.zeros(n_experiments)
        h_ci_results = np.zeros(n_experiments)
        
        # å¹¶å‘æ‰§è¡Œ
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_index = {executor.submit(_run_single_adaptive_experiment, *args): i 
                             for i, args in enumerate(task_args)}
            
            # æ”¶é›†ç»“æœ
            for future in tqdm(as_completed(future_to_index), total=n_experiments, desc="è‡ªé€‚åº”PGAEå¹¶å‘å®éªŒ"):
                index = future_to_index[future]
                try:
                    tau, l_ci, h_ci = future.result()
                    tau_results[index] = tau
                    l_ci_results[index] = l_ci
                    h_ci_results[index] = h_ci
                except Exception as exc:
                    logger.error(f'å®éªŒ {index} ç”Ÿæˆå¼‚å¸¸: {exc}')
                    # è®¾ç½®é»˜è®¤å€¼ï¼Œé¿å…ç¨‹åºå´©æºƒ
                    tau_results[index] = 0.0
                    l_ci_results[index] = 0.0  
                    h_ci_results[index] = 0.0
                
                # å†…å­˜æ¸…ç†
                if index % 50 == 0:
                    gc.collect()
        
        return tau_results, l_ci_results, h_ci_results

    def save_results(self, results: Dict, filename: str = None) -> str:
        """
        ä¿å­˜å®éªŒç»“æœ
        
        Args:
            results: å®éªŒç»“æœå­—å…¸
            filename: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶å
        """
        if filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f'adaptive_pgae_results_{timestamp}.json'
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®ï¼ˆç§»é™¤numpyæ•°ç»„ï¼‰
        save_data = {
            'method': results['method'],
            'mse': results['mse'],
            'bias': results['bias'],
            'variance': results['variance'],
            'avg_ci_length': results['avg_ci_length'],
            'coverage_rate': results['coverage_rate'],
            'true_value': results['true_value'],
            'execution_time': results['execution_time'],
            'parameters': results['parameters'],
            'summary_statistics': {
                'mean_tau': float(np.mean(results['tau_estimates'])),
                'std_tau': float(np.std(results['tau_estimates'])),
                'mean_ci_length': float(np.mean(results['h_ci'] - results['l_ci'])),
                'min_tau': float(np.min(results['tau_estimates'])),
                'max_tau': float(np.max(results['tau_estimates']))
            }
        }
        
        import json
        with open(filename, 'w') as f:
            json.dump(save_data, f, indent=2)
        
        logger.info(f"è‡ªé€‚åº”PGAEç»“æœå·²ä¿å­˜: {filename}")
        return filename

# ç‹¬ç«‹çš„workerå‡½æ•°ï¼Œç”¨äºå¹¶å‘æ‰§è¡Œ
def _run_single_adaptive_experiment(df_prepared: pd.DataFrame, X: List[str], F: str, Y: str,
                                   gamma: float, batch_size: int,
                                   design_update_freq: int, warmup_batches: int,
                                   n_true_labels: int, 
                                   alpha: float, seed: Optional[int]) -> Tuple[float, float, float]:
    """
    è¿è¡Œå•ä¸ªè‡ªé€‚åº”PGAEå®éªŒçš„workerå‡½æ•°
    
    Args:
        df_prepared: å‡†å¤‡å¥½çš„æ•°æ®æ¡†
        X: åå˜é‡åˆ—ååˆ—è¡¨
        F: é¢„æµ‹åˆ—å
        Y: çœŸå®æ ‡ç­¾åˆ—å
        gamma: PGAEå‚æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        n_true_labels: ç›®æ ‡çœŸå®æ ‡ç­¾æ•°é‡
        alpha: ç½®ä¿¡æ°´å¹³
        seed: éšæœºç§å­
        
    Returns:
        (ä¼°è®¡å€¼, ç½®ä¿¡åŒºé—´ä¸‹ç•Œ, ç½®ä¿¡åŒºé—´ä¸Šç•Œ)
    """
    try:
        if seed is not None:
            np.random.seed(seed)
        
        df_work = df_prepared.copy()
        df_work['true_label'] = 0
        
        cnt_true = 0
        PGAE_df = pd.DataFrame()
        
        # åˆå§‹åŒ–è®¾è®¡
        initial_design = get_PGAE_design(df_work, X, F, Y, gamma)
        initial_design['accept_prob'] = 1
        initial_design['exp_prob'] = 1
        df_work = overwrite_merge(df_work, initial_design, on=X, how='left')
        df_work['sample_pmf'] = df_work['true_pmf']
        
        batch_count = 0
        while cnt_true < n_true_labels:
            # ä½¿ç”¨æ‹’ç»é‡‡æ ·
            sampled_df = rejection_sample(df_work, df_work.columns.tolist(), 'accept_prob', 
                                        n_samples=batch_size)
            
            # æ ¹æ®å®éªŒæ¦‚ç‡å†³å®šæ˜¯å¦æ ‡è®°
            u = np.random.uniform(0, 1, size=len(sampled_df))
            sampled_df['true_label'] = (u < sampled_df['exp_prob']).astype(int)
            
            batch_true = sampled_df['true_label'].sum()
            cnt_true += batch_true
            PGAE_df = pd.concat([PGAE_df, sampled_df], ignore_index=True)
            
            batch_count += 1
            # å¦‚æœæœ‰è¶³å¤Ÿçš„æ ‡è®°æ•°æ®ï¼ŒæŒ‰é¢„çƒ­ä¸é¢‘ç‡ç­–ç•¥æ›´æ–°è®¾è®¡
            if len(PGAE_df[PGAE_df['true_label'] == 1]) > 0:
                try:
                    if batch_count > max(0, int(warmup_batches)):
                        if batch_count % max(1, int(design_update_freq)) == 0:
                            updated_design = get_PGAE_design(PGAE_df, X, F, Y, gamma)
                            df_work = overwrite_merge(df_work, updated_design, on=X, how='left')
                except Exception:
                    # å¦‚æœè®¾è®¡æ›´æ–°å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰è®¾è®¡
                    pass
        
        # æˆªæ–­åˆ°ç›®æ ‡æ ‡ç­¾æ•°é‡
        if cnt_true > n_true_labels:
            PGAE_df['cum_sum'] = PGAE_df['true_label'].cumsum()
            cutoff_mask = PGAE_df['cum_sum'] <= n_true_labels
            PGAE_df = PGAE_df[cutoff_mask]
        
        # è®¡ç®—ä¼°è®¡å€¼å’Œç½®ä¿¡åŒºé—´ - é‡‡æ ·å®Œæˆåä½¿ç”¨regular PGAEçš„CVæ–¹æ³•
        tau, l_ci, h_ci = PGAE_est_ci(PGAE_df, X, F, Y, alpha=alpha, K=3)
        
        # å†…å­˜æ¸…ç†
        del PGAE_df, df_work
        gc.collect()
        
        return tau, l_ci, h_ci
        
    except Exception as e:
        # è®°å½•å¼‚å¸¸ä½†è¿”å›é»˜è®¤å€¼ä»¥ä¿æŒç¨³å®šæ€§
        print(f"è‡ªé€‚åº”PGAE Workerå¼‚å¸¸: {e}")
        return 0.0, 0.0, 0.0

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    import time
    
    # ç›®æ ‡é…ç½®
    TARGET_CONFIGS = {
        'ECON1MOD': {
            'X': ['EDUCATION'],
            'F': 'ECON1MOD_LLM',
            'Y': 'ECON1MOD',
            'description': 'Economic conditions rating (1-4)'
        },
        'UNITY': {
            'X': ['EDUCATION'],
            'F': 'UNITY_LLM',
            'Y': 'UNITY',
            'description': 'US unity perception (1-2)'
        },
        'GPT1': {
            'X': ['EDUCATION'],
            'F': 'GPT1_LLM',
            'Y': 'GPT1',
            'description': 'ChatGPT familiarity (1-3)'
        },
        'MOREGUNIMPACT': {
            'X': ['EDUCATION'],
            'F': 'MOREGUNIMPACT_LLM',
            'Y': 'MOREGUNIMPACT',
            'description': 'Gun control impact (1-3)'
        },
        'GAMBLERESTR': {
            'X': ['EDUCATION'],
            'F': 'GAMBLERESTR_LLM',
            'Y': 'GAMBLERESTR',
            'description': 'Gambling restriction opinion (1-3)'
        }
    }
    
    parser = argparse.ArgumentParser(description='è‡ªé€‚åº”PGAEä¼°è®¡å™¨')
    parser.add_argument('data_file', help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--target', '-t', default='ECON1MOD', 
                       choices=list(TARGET_CONFIGS.keys()),
                       help='é¢„æµ‹ç›®æ ‡ (é»˜è®¤: ECON1MOD)')
    parser.add_argument('--experiments', '-e', type=int, default=100,
                       help='å®éªŒæ¬¡æ•° (é»˜è®¤: 100)')
    parser.add_argument('--labels', '-l', type=int, default=500,
                       help='æ¯æ¬¡å®éªŒçš„çœŸå®æ ‡ç­¾æ•°é‡ (é»˜è®¤: 500)')
    parser.add_argument('--gamma', '-g', type=float, default=0.5,
                       help='PGAE gammaå‚æ•° (é»˜è®¤: 0.5)')
    parser.add_argument('--alpha', '-a', type=float, default=0.90,
                       help='ç½®ä¿¡æ°´å¹³ (é»˜è®¤: 0.90)')
    parser.add_argument('--seed', '-s', type=int, default=42,
                       help='éšæœºç§å­ (é»˜è®¤: 42)')
    parser.add_argument('--batch-size', '-b', type=int, default=100,
                       help='æ‰¹å¤§å° (é»˜è®¤: 100)')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--concurrent', action='store_true',
                       help='ä½¿ç”¨å¹¶å‘æ‰§è¡Œ')
    
    args = parser.parse_args()
    
    # è·å–ç›®æ ‡é…ç½®
    config = TARGET_CONFIGS[args.target]
    
    # åŠ è½½æ•°æ®
    logger.info(f"åŠ è½½æ•°æ®: {args.data_file}")
    df = pd.read_csv(args.data_file)
    
    logger.info(f"ç›®æ ‡: {args.target} - {config['description']}")
    
    # åˆå§‹åŒ–ä¼°è®¡å™¨
    estimator = AdaptivePGAEEstimator(
        X=config['X'],
        F=config['F'],
        Y=config['Y'],
        gamma=args.gamma,
        batch_size=args.batch_size
    )
    
    # è¿è¡Œå®éªŒ
    results = estimator.run_experiments(
        df, 
        n_experiments=args.experiments,
        n_true_labels=args.labels,
        alpha=args.alpha,
        seed=args.seed,
        use_concurrent=args.concurrent
    )
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    output_file = args.output
    if output_file is None:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_file = f'adaptive_pgae_{args.target.lower()}_{timestamp}.json'
    
    # ä¿å­˜ç»“æœ
    saved_file = estimator.save_results(results, output_file)
    
    print(f"\nâœ… è‡ªé€‚åº”PGAEå®éªŒå®Œæˆ!")
    print(f"ç›®æ ‡: {args.target}")
    print(f"å®éªŒè®¾ç½®: {args.experiments} experiments, {args.labels} labels per experiment")
    print(f"ç»“æœæ–‡ä»¶: {saved_file}")

if __name__ == "__main__":
    main()
