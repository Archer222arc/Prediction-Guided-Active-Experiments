#!/usr/bin/env python3
"""
PGAEå’ŒAdaptive PGAE RandomForestå‚æ•°è°ƒä¼˜
ä¸æ”¹å˜ç®—æ³•æœ¬è´¨ï¼Œåªè°ƒä¼˜RandomForestå‚æ•°
ä¸ºä¸¤ä¸ªä¼°è®¡å™¨åˆ†åˆ«å¯»æ‰¾æœ€ä¼˜å‚æ•°ç»„åˆ
"""

import numpy as np
import pandas as pd
import time
import json
import shutil
import importlib
import os
import sys
from typing import Dict, List, Tuple
from tqdm import tqdm

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
UTILS_PATH = os.path.join(SCRIPT_DIR, 'utils.py')
UTILS_BACKUP_PATH = os.path.join(SCRIPT_DIR, 'utils_backup.py')

def backup_utils():
    """å¤‡ä»½estimators/utils.pyæ–‡ä»¶ï¼ˆæŒ‰è„šæœ¬æ‰€åœ¨ç›®å½•è®¡ç®—ï¼‰"""
    shutil.copy(UTILS_PATH, UTILS_BACKUP_PATH)
    print("å·²å¤‡ä»½estimators/utils.pyä¸ºestimators/utils_backup.py")

def restore_utils():
    """æ¢å¤estimators/utils.pyæ–‡ä»¶"""
    if os.path.exists(UTILS_BACKUP_PATH):
        shutil.copy(UTILS_BACKUP_PATH, UTILS_PATH)
        print("å·²æ¢å¤estimators/utils.py")
    else:
        print("æœªæ‰¾åˆ°estimators/utils_backup.pyï¼Œè·³è¿‡æ¢å¤")

def modify_utils_rf_params(pgae_params: Dict, adaptive_params: Dict):
    """
    ä¿®æ”¹utils.pyä¸­çš„RandomForestå‚æ•°
    
    Args:
        pgae_params: PGAEçš„RandomForestå‚æ•°
        adaptive_params: Adaptive PGAEçš„RandomForestå‚æ•°
    """
    with open(UTILS_PATH, 'r') as f:
        content = f.read()
    
    # æ„å»ºå‚æ•°å­—ç¬¦ä¸²
    def params_to_str(params):
        return ', '.join([f'{k}={v}' for k, v in params.items()])
    
    pgae_params_str = params_to_str(pgae_params)
    adaptive_params_str = params_to_str(adaptive_params)
    
    lines = content.split('\n')
    in_pgae_function = False
    in_adaptive_function = False
    
    for i, line in enumerate(lines):
        # æ£€æµ‹å‡½æ•°èŒƒå›´
        if 'def PGAE_est_ci(' in line:
            in_pgae_function = True
            in_adaptive_function = False
        elif 'def adaptive_PGAE_est_ci(' in line:
            in_adaptive_function = True
            in_pgae_function = False
        elif line.startswith('def ') and not line.startswith('    '):
            in_pgae_function = False
            in_adaptive_function = False
            
        # æ›¿æ¢å‚æ•°
        if 'model_mu = RandomForestRegressor(' in line:
            if in_pgae_function:
                lines[i] = f"        model_mu = RandomForestRegressor({pgae_params_str})"
                print(f"æ›¿æ¢PGAE model_mu: {lines[i].strip()}")
            elif in_adaptive_function:
                lines[i] = f"        model_mu = RandomForestRegressor({adaptive_params_str})"
                print(f"æ›¿æ¢Adaptive model_mu: {lines[i].strip()}")
        elif 'model_tau = RandomForestRegressor(' in line:
            if in_pgae_function:
                lines[i] = f"        model_tau = RandomForestRegressor({pgae_params_str})"
                print(f"æ›¿æ¢PGAE model_tau: {lines[i].strip()}")
            elif in_adaptive_function:
                lines[i] = f"        model_tau = RandomForestRegressor({adaptive_params_str})"
                print(f"æ›¿æ¢Adaptive model_tau: {lines[i].strip()}")
        elif 'final_model_mu = RandomForestRegressor(' in line and in_adaptive_function:
            lines[i] = f"        final_model_mu = RandomForestRegressor({adaptive_params_str})"
            print(f"æ›¿æ¢Adaptive final_model_mu: {lines[i].strip()}")
    
    with open(UTILS_PATH, 'w') as f:
        f.write('\n'.join(lines))
    
    print(f"å‚æ•°ä¿®æ”¹å®Œæˆï¼šPGAE({pgae_params_str}), Adaptive({adaptive_params_str})")

def test_single_rf_combination(df: pd.DataFrame, target_config: Dict, 
                              pgae_params: Dict, adaptive_params: Dict,
                              n_experiments: int = 15) -> Dict:
    """
    æµ‹è¯•å•ä¸ªRandomForestå‚æ•°ç»„åˆ
    
    Args:
        df: æ•°æ®DataFrame
        target_config: ç›®æ ‡é…ç½® 
        pgae_params: PGAEçš„RandomForestå‚æ•°
        adaptive_params: Adaptive PGAEçš„RandomForestå‚æ•°
        n_experiments: å®éªŒæ¬¡æ•°
    
    Returns:
        æµ‹è¯•ç»“æœ
    """
    # ä¿®æ”¹utils.pyä¸­çš„å‚æ•°
    modify_utils_rf_params(pgae_params, adaptive_params)
    
    # ä½¿æ¨¡å—ç¼“å­˜å¤±æ•ˆå¹¶å¼ºåˆ¶é‡æ–°å¯¼å…¥ï¼Œç¡®ä¿æ–°å‚æ•°ç”Ÿæ•ˆ
    importlib.invalidate_caches()
    for name in ['utils', 'adaptive_pgae_estimator', 'pgae_estimator']:
        if name in sys.modules:
            del sys.modules[name]

    # ç¡®ä¿estimatorsç›®å½•åœ¨æœç´¢è·¯å¾„å‰åˆ—ï¼Œä»¥åŠ è½½æœ¬ç›®å½•ä¸‹çš„utils.py
    if SCRIPT_DIR not in sys.path:
        sys.path.insert(0, SCRIPT_DIR)
    # åŒæ—¶é€šè¿‡ç¯å¢ƒå˜é‡å½±å“å­è¿›ç¨‹çš„å¯¼å…¥æœç´¢è·¯å¾„ï¼ˆå¹¶å‘æ‰§è¡Œæ—¶ç”Ÿæ•ˆï¼‰
    current_pp = os.environ.get('PYTHONPATH', '')
    if SCRIPT_DIR not in current_pp.split(os.pathsep):
        os.environ['PYTHONPATH'] = (SCRIPT_DIR + (os.pathsep + current_pp if current_pp else ''))

    adaptive_pgae_estimator = importlib.import_module('adaptive_pgae_estimator')
    pgae_estimator = importlib.import_module('pgae_estimator')
    
    results = {}
    
    try:
        # æµ‹è¯•PGAE
        print(f"    æµ‹è¯•PGAE...")
        pgae_estimator_class = pgae_estimator.PGAEEstimator
        pgae_est = pgae_estimator_class(
            X=target_config['X'],
            F=target_config['F'],
            Y=target_config['Y'],
            gamma=0.5
        )
        
        start_time = time.time()
        pgae_results = pgae_est.run_experiments(
            df, n_experiments=n_experiments, n_true_labels=500, alpha=0.9, 
            seed=42, use_concurrent=True, max_workers=6
        )
        pgae_time = time.time() - start_time
        
        results['pgae'] = {
            'mse': pgae_results['mse'],
            'bias': pgae_results['bias'],
            'variance': pgae_results['variance'],
            'coverage_rate': pgae_results['coverage_rate'],
            'time': pgae_time
        }
        
        # æµ‹è¯•Adaptive PGAE
        print(f"    æµ‹è¯•Adaptive PGAE...")
        adaptive_estimator_class = adaptive_pgae_estimator.AdaptivePGAEEstimator
        adaptive_est = adaptive_estimator_class(
            X=target_config['X'],
            F=target_config['F'],
            Y=target_config['Y'],
            gamma=0.5,
            batch_size=250
        )
        
        start_time = time.time()
        adaptive_results = adaptive_est.run_experiments(
            df, n_experiments=n_experiments, n_true_labels=500, alpha=0.9,
            seed=42, use_concurrent=True, max_workers=6
        )
        adaptive_time = time.time() - start_time
        
        results['adaptive'] = {
            'mse': adaptive_results['mse'],
            'bias': adaptive_results['bias'],
            'variance': adaptive_results['variance'],
            'coverage_rate': adaptive_results['coverage_rate'],
            'time': adaptive_time
        }
        
    except Exception as e:
        print(f"    æµ‹è¯•å¤±è´¥: {e}")
        results['error'] = str(e)
    
    return results

def test_rf_parameters(data_file: str, target: str = 'ECON1MOD') -> Dict:
    """
    æµ‹è¯•ä¸åŒRandomForestå‚æ•°ç»„åˆï¼Œä¸ºPGAEå’ŒAdaptive PGAEåˆ†åˆ«å¯»æ‰¾æœ€ä¼˜å‚æ•°
    """
    # åŠ è½½æ•°æ®
    df = pd.read_csv(data_file)
    
    # ç›®æ ‡é…ç½®
    TARGET_CONFIGS = {
        'ECON1MOD': {
            'X': ['EDUCATION'],
            'F': 'ECON1MOD_LLM',
            'Y': 'ECON1MOD',
        }
    }
    config = TARGET_CONFIGS[target]
    
    # å®šä¹‰è¦æµ‹è¯•çš„RFå‚æ•°ç»„åˆ
    rf_configs = [
        # å½“å‰é»˜è®¤é…ç½®
        {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'random_state': 42, 'name': 'default'},
        
        # ä¿å®ˆé…ç½®ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
        {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'random_state': 42, 'name': 'conservative'},
        
        # å¢å¼ºé…ç½®ï¼ˆæ›´å¤šæ ‘ï¼‰
        {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'random_state': 42, 'name': 'enhanced'},
        
        # ç¨³å®šé…ç½®ï¼ˆä¸­ç­‰å‚æ•°ï¼‰
        {'n_estimators': 100, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 2, 'random_state': 42, 'name': 'stable'},
        
        # è½»é‡é…ç½®ï¼ˆæ›´å¿«è®­ç»ƒï¼‰
        {'n_estimators': 30, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5, 'random_state': 42, 'name': 'lightweight'},
        
        # å¹³è¡¡é…ç½®
        {'n_estimators': 75, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'random_state': 42, 'name': 'balanced'}
    ]
    
    print(f"æµ‹è¯• {len(rf_configs)} ä¸ªRandomForestå‚æ•°é…ç½®...")
    print("å°†ä¸ºPGAEå’ŒAdaptive PGAEåˆ†åˆ«å¯»æ‰¾æœ€ä¼˜å‚æ•°ç»„åˆ")
    
    # å¤‡ä»½åŸå§‹utils.py
    backup_utils()
    
    all_results = {}
    
    try:
        for i, rf_config in enumerate(tqdm(rf_configs, desc="Testing RF configs")):
            config_name = rf_config['name']
            
            print(f"\né…ç½® {i+1}/{len(rf_configs)}: {config_name}")
            print(f"  å‚æ•°: n_est={rf_config['n_estimators']}, max_depth={rf_config.get('max_depth', 'None')}")
            print(f"        min_split={rf_config['min_samples_split']}, min_leaf={rf_config['min_samples_leaf']}")
            
            # ç§»é™¤nameå­—æ®µç”¨äºå‚æ•°ä¼ é€’
            params = {k: v for k, v in rf_config.items() if k != 'name'}
            
            # æµ‹è¯•è¯¥å‚æ•°ç»„åˆ (PGAEå’ŒAdaptive PGAEä½¿ç”¨ç›¸åŒå‚æ•°)
            results = test_single_rf_combination(df, config, params, params, n_experiments=12)
            
            all_results[config_name] = {
                'params': rf_config,
                'results': results
            }
            
            if 'error' not in results:
                print(f"  PGAE - MSE: {results['pgae']['mse']:.6f}, è¦†ç›–ç‡: {results['pgae']['coverage_rate']:.3f}")
                print(f"  Adaptive - MSE: {results['adaptive']['mse']:.6f}, è¦†ç›–ç‡: {results['adaptive']['coverage_rate']:.3f}")
            else:
                print(f"  å¤±è´¥: {results['error']}")
    
    finally:
        # æ¢å¤åŸå§‹utils.py
        restore_utils()
    
    return all_results

def analyze_results(all_results: Dict):
    """åˆ†æè°ƒå‚ç»“æœå¹¶ç»™å‡ºå»ºè®®"""
    print("\n" + "="*100)
    print("RANDOMFOREST PARAMETER TUNING RESULTS")
    print("="*100)
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_results = {k: v for k, v in all_results.items() if 'error' not in v['results']}
    
    if not valid_results:
        print("âŒ æ‰€æœ‰å‚æ•°ç»„åˆæµ‹è¯•å‡å¤±è´¥")
        return
    
    # æŒ‰PGAE MSEæ’åº
    pgae_sorted = sorted(valid_results.items(), key=lambda x: x[1]['results']['pgae']['mse'])
    
    # æŒ‰Adaptive PGAE MSEæ’åº  
    adaptive_sorted = sorted(valid_results.items(), key=lambda x: x[1]['results']['adaptive']['mse'])
    
    print(f"\nğŸ† PGAE æœ€ä½³å‚æ•°æ’å:")
    print(f"{'Rank':<5} {'Config':<12} {'MSE':<12} {'Coverage':<10} {'n_est':<6} {'max_depth':<10} {'min_split':<10}")
    print("-" * 85)
    
    for rank, (config_name, config_data) in enumerate(pgae_sorted[:3], 1):
        params = config_data['params']
        results = config_data['results']['pgae']
        print(f"{rank:<5} {config_name:<12} {results['mse']:<12.6f} {results['coverage_rate']:<10.3f} "
              f"{params['n_estimators']:<6} {str(params['max_depth']):<10} {params['min_samples_split']:<10}")
    
    print(f"\nğŸ† Adaptive PGAE æœ€ä½³å‚æ•°æ’å:")
    print(f"{'Rank':<5} {'Config':<12} {'MSE':<12} {'Coverage':<10} {'n_est':<6} {'max_depth':<10} {'min_split':<10}")
    print("-" * 85)
    
    for rank, (config_name, config_data) in enumerate(adaptive_sorted[:3], 1):
        params = config_data['params']
        results = config_data['results']['adaptive']
        print(f"{rank:<5} {config_name:<12} {results['mse']:<12.6f} {results['coverage_rate']:<10.3f} "
              f"{params['n_estimators']:<6} {str(params['max_depth']):<10} {params['min_samples_split']:<10}")
    
    # æ¨èæœ€ä½³å‚æ•°
    best_pgae = pgae_sorted[0]
    best_adaptive = adaptive_sorted[0]
    
    print(f"\nâœ… æœ€ç»ˆæ¨è:")
    print(f"PGAE æœ€ä½³é…ç½®: {best_pgae[0]} (MSE: {best_pgae[1]['results']['pgae']['mse']:.6f})")
    pgae_params = best_pgae[1]['params']
    print(f"  å‚æ•°: {', '.join([f'{k}={v}' for k, v in pgae_params.items() if k != 'name'])}")
    
    print(f"\nAdaptive PGAE æœ€ä½³é…ç½®: {best_adaptive[0]} (MSE: {best_adaptive[1]['results']['adaptive']['mse']:.6f})")
    adaptive_params = best_adaptive[1]['params']  
    print(f"  å‚æ•°: {', '.join([f'{k}={v}' for k, v in adaptive_params.items() if k != 'name'])}")
    
    print(f"\nğŸ“ åº”ç”¨å»ºè®®:")
    print(f"åœ¨estimators/utils.pyä¸­åˆ†åˆ«è®¾ç½®ä¸åŒçš„RandomForestå‚æ•°:")
    print(f"1. PGAE_est_ci ä¸­çš„ model_mu ä¸ model_tau:")
    pgae_str = ', '.join([f'{k}={v}' for k, v in pgae_params.items() if k != 'name'])
    print(f"   RandomForestRegressor({pgae_str})")
    
    print(f"\n2. adaptive_PGAE_est_ci ä¸­çš„ model_mu ä¸ model_tau:")
    adaptive_str = ', '.join([f'{k}={v}' for k, v in adaptive_params.items() if k != 'name'])
    print(f"   RandomForestRegressor({adaptive_str})")

def main():
    """ä¸»å‡½æ•° - RandomForestå‚æ•°è°ƒä¼˜"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python tune_adaptive_rf.py <data_file>")
        print("  python tune_adaptive_rf.py data/NPORS_2024_for_public_release_with_LLM_prediction.csv")
        return
    
    data_file = sys.argv[1]
    print("="*100)
    print("PGAE & ADAPTIVE PGAE RANDOMFOREST PARAMETER TUNING")
    print("="*100)
    print(f"æ•°æ®æ–‡ä»¶: {data_file}")
    print("ç›®æ ‡: ä¸ºPGAEå’ŒAdaptive PGAEåˆ†åˆ«å¯»æ‰¾æœ€ä¼˜RandomForestå‚æ•°")
    
    # è¿è¡Œè°ƒå‚å®éªŒ
    all_results = test_rf_parameters(data_file)
    
    # åˆ†æç»“æœ
    analyze_results(all_results)
    
    # ä¿å­˜ç»“æœ
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_file = f'rf_parameter_tuning_results_{timestamp}.json'
    
    # è½¬æ¢numpyç±»å‹
    def convert_numpy(obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {key: convert_numpy(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy(item) for item in obj]
        return obj
    
    with open(output_file, 'w') as f:
        json.dump(convert_numpy(all_results), f, indent=2)
    
    print(f"\nâœ… è°ƒå‚å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()
