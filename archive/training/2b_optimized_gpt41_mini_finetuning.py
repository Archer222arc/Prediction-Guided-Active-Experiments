#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆ GPT-4.1-mini å¾®è°ƒè„šæœ¬
åŸºäºä¸“å®¶å»ºè®®ä¼˜åŒ–è¶…å‚æ•°å’Œè®­ç»ƒç›‘æ§
"""

import os
import time
import json
from openai import OpenAI

def create_optimized_finetuning_job():
    """åˆ›å»ºä¼˜åŒ–çš„å¾®è°ƒä½œä¸š"""
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–Azureä¿¡æ¯
    with open("config/azure_models_config.json", 'r') as f:
        config = json.load(f)
    
    azure_config = config["azure_endpoints"]["north_central_us"]
    
    client = OpenAI(
        api_key=azure_config["api_key"],
        base_url=azure_config["endpoint"].rstrip("/") + "/openai/v1/"
    )
    
    print("=== ä¼˜åŒ–ç‰ˆ Azure OpenAI GPT-4.1-mini å¾®è°ƒ ===")
    print(f"æ•°æ®é›†å¤§å°: 21,852 è®­ç»ƒæ ·æœ¬ + 5,463 éªŒè¯æ ·æœ¬")
    
    # ä¸Šä¼ æ–‡ä»¶
    print("\nä¸Šä¼ è®­ç»ƒæ–‡ä»¶...")
    tr = client.files.create(
        file=open("finetuning_data/train.jsonl", "rb"), 
        purpose="fine-tune"
    )
    print(f"è®­ç»ƒæ–‡ä»¶ID: {tr.id}")
    
    print("ä¸Šä¼ éªŒè¯æ–‡ä»¶...")
    vr = client.files.create(
        file=open("finetuning_data/validation.jsonl", "rb"), 
        purpose="fine-tune"
    )
    print(f"éªŒè¯æ–‡ä»¶ID: {vr.id}")
    
    # ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ
    print("\nç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ...")
    def wait_for_file_processing(client, file_id, max_wait=300):
        start_time = time.time()
        while time.time() - start_time < max_wait:
            file_info = client.files.retrieve(file_id)
            if file_info.status == 'processed':
                return True
            elif file_info.status == 'error':
                raise Exception(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {file_id}")
            time.sleep(5)
        return False
    
    if not wait_for_file_processing(client, tr.id):
        raise Exception("è®­ç»ƒæ–‡ä»¶å¤„ç†è¶…æ—¶")
    if not wait_for_file_processing(client, vr.id):
        raise Exception("éªŒè¯æ–‡ä»¶å¤„ç†è¶…æ—¶")
    
    print("âœ… æ–‡ä»¶å¤„ç†å®Œæˆ")
    
    # ä¼˜åŒ–çš„è¶…å‚æ•°è®¾ç½®
    optimized_hyperparams = {
        "n_epochs": 3,
        "batch_size": -1,  # è‡ªåŠ¨é€‰æ‹©ï¼Œé¢„è®¡ ~44 (21,852 * 0.2% = 44)
        "learning_rate_multiplier": 0.1  # é€‚ä¸­çš„å­¦ä¹ ç‡
    }
    
    print(f"\n=== ä¼˜åŒ–çš„è¶…å‚æ•°è®¾ç½® ===")
    print(f"Epochs: {optimized_hyperparams['n_epochs']}")
    print(f"Batch Size: è‡ªåŠ¨ (é¢„è®¡ ~44)")
    print(f"Learning Rate Multiplier: {optimized_hyperparams['learning_rate_multiplier']}")
    print(f"é¢„è®¡æ€»æ­¥æ•°: ~1,491 (vs ä¹‹å‰çš„ 65,556)")
    
    # åˆ›å»ºå¾®è°ƒä½œä¸š
    print("\nåˆ›å»ºä¼˜åŒ–å¾®è°ƒä½œä¸š...")
    job = client.fine_tuning.jobs.create(
        training_file=tr.id,
        validation_file=vr.id,
        model="gpt-4.1-mini-2025-04-14",
        suffix="npors-predictor-optimized",
        hyperparameters=optimized_hyperparams
    )
    
    print(f"âœ… ä¼˜åŒ–å¾®è°ƒä½œä¸šåˆ›å»ºæˆåŠŸ!")
    print(f"ä½œä¸šID: {job.id}")
    print(f"æ¨¡å‹: {job.model}")
    print(f"çŠ¶æ€: {job.status}")
    
    # ä¿å­˜ä½œä¸šä¿¡æ¯
    job_info = {
        "job_id": job.id,
        "model": job.model,
        "training_file": tr.id,
        "validation_file": vr.id,
        "hyperparameters": optimized_hyperparams,
        "created_at": job.created_at,
        "expected_steps": "~1,491",
        "optimization_notes": "ä½¿ç”¨è‡ªåŠ¨batch_sizeå’Œä¼˜åŒ–å­¦ä¹ ç‡"
    }
    
    with open("optimized_finetuning_job.json", "w") as f:
        json.dump(job_info, f, indent=2)
    
    print(f"ä½œä¸šä¿¡æ¯ä¿å­˜åˆ°: optimized_finetuning_job.json")
    
    return job.id

def monitor_optimized_job():
    """ç›‘æ§ä¼˜åŒ–ç‰ˆå¾®è°ƒä½œä¸šï¼Œé‡ç‚¹å…³æ³¨è®­ç»ƒæŒ‡æ ‡"""
    
    with open("optimized_finetuning_job.json", "r") as f:
        job_info = json.load(f)
    
    job_id = job_info["job_id"]
    
    with open("config/azure_models_config.json", 'r') as f:
        config = json.load(f)
    
    azure_config = config["azure_endpoints"]["north_central_us"]
    
    client = OpenAI(
        api_key=azure_config["api_key"],
        base_url=azure_config["endpoint"].rstrip("/") + "/openai/v1/"
    )
    
    print(f"=== ç›‘æ§ä¼˜åŒ–å¾®è°ƒä½œä¸š ===")
    print(f"ä½œä¸šID: {job_id}")
    print(f"é¢„è®¡æ­¥æ•°: ~1,491 (vs ä¹‹å‰65,556)")
    
    while True:
        job_status = client.fine_tuning.jobs.retrieve(job_id)
        current_time = time.strftime('%X')
        
        print(f"[{current_time}] çŠ¶æ€: {job_status.status}")
        
        # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(job_status, 'trained_tokens') and job_status.trained_tokens:
            print(f"  å·²è®­ç»ƒtokens: {job_status.trained_tokens:,}")
        
        if job_status.status in ("succeeded", "failed", "cancelled"):
            break
            
        if job_status.status == "running":
            print("  ğŸ”„ è®­ç»ƒä¸­... (ä½¿ç”¨ä¼˜åŒ–å‚æ•°ï¼Œé¢„è®¡æ›´å¿«å®Œæˆ)")
            
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    
    if job_status.status == "succeeded":
        print(f"âœ… ä¼˜åŒ–å¾®è°ƒå®Œæˆ!")
        print(f"Fine-tunedæ¨¡å‹: {job_status.fine_tuned_model}")
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_result = {
            "job_id": job_id,
            "status": job_status.status,
            "fine_tuned_model": job_status.fine_tuned_model,
            "created_at": job_status.created_at,
            "finished_at": job_status.finished_at,
            "hyperparameters": job_status.hyperparameters.__dict__ if job_status.hyperparameters else None,
            "result_files": job_status.result_files,
            "optimization_used": True
        }
        
        with open("optimized_finetuning_result.json", "w") as f:
            json.dump(final_result, f, indent=2)
        
        print("ç»“æœä¿å­˜åˆ°: optimized_finetuning_result.json")
        
        # ä¸‹è½½è®­ç»ƒç»“æœæ–‡ä»¶
        if job_status.result_files:
            print("\nä¸‹è½½è®­ç»ƒç»“æœ...")
            for file_id in job_status.result_files:
                try:
                    content = client.files.content(file_id)
                    filename = f"training_results_optimized_{file_id}.csv"
                    with open(filename, "wb") as f:
                        f.write(content.read())
                    print(f"è®­ç»ƒç»“æœå·²ä¸‹è½½: {filename}")
                    print("âš ï¸ æ£€æŸ¥ train_loss/valid_loss æ›²çº¿ä»¥è¯„ä¼°è®­ç»ƒè´¨é‡")
                except Exception as e:
                    print(f"ä¸‹è½½ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        
        return job_status.fine_tuned_model
        
    else:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {job_status.status}")
        if job_status.error:
            print(f"é”™è¯¯: {job_status.error}")
        return None

def compare_approaches():
    """æ¯”è¾ƒåŸå§‹æ–¹æ³•vsä¼˜åŒ–æ–¹æ³•"""
    print("=== è®­ç»ƒæ–¹æ³•å¯¹æ¯” ===")
    print("åŸå§‹è®¾ç½®:")
    print("  batch_size: 1")
    print("  learning_rate_multiplier: 1.0") 
    print("  é¢„è®¡æ­¥æ•°: 65,556 (21,852 Ã— 3)")
    print("  è®­ç»ƒæ—¶é—´: é•¿")
    print()
    print("ä¼˜åŒ–è®¾ç½®:")
    print("  batch_size: -1 (è‡ªåŠ¨, ~44)")
    print("  learning_rate_multiplier: 0.1")
    print("  é¢„è®¡æ­¥æ•°: ~1,491 (âŒˆ21,852/44âŒ‰ Ã— 3)")
    print("  è®­ç»ƒæ—¶é—´: å¤§å¹…ç¼©çŸ­")
    print("  æ”¶æ•›æ€§: æ›´å¥½")

def main():
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python 2b_optimized_gpt41_mini_finetuning.py create     # åˆ›å»ºä¼˜åŒ–å¾®è°ƒä½œä¸š")
        print("  python 2b_optimized_gpt41_mini_finetuning.py monitor    # ç›‘æ§ä¼˜åŒ–ä½œä¸š")
        print("  python 2b_optimized_gpt41_mini_finetuning.py compare    # å¯¹æ¯”è®­ç»ƒæ–¹æ³•")
        return
    
    action = sys.argv[1]
    
    try:
        if action == "create":
            create_optimized_finetuning_job()
        elif action == "monitor":
            monitor_optimized_job()
        elif action == "compare":
            compare_approaches()
        else:
            print(f"æœªçŸ¥æ“ä½œ: {action}")
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    main()