#!/usr/bin/env python3
"""
å¿«é€Ÿå¯¹æ¯”åˆ†æ - å°†å¾®è°ƒç»“æœä¸åŸºçº¿ç»“æœåˆå¹¶åˆ†æ
"""

import pandas as pd
import numpy as np
import json

def merge_and_analyze_results():
    """åˆå¹¶å¾®è°ƒç»“æœå’ŒåŸºçº¿ç»“æœå¹¶åˆ†æ"""
    
    # åŠ è½½å¾®è°ƒé¢„æµ‹ç»“æœ
    print("åŠ è½½å¾®è°ƒé¢„æµ‹ç»“æœ...")
    finetuned_df = pd.read_csv('comparison_results_sample_20.csv')
    
    # åŠ è½½åŸºçº¿é¢„æµ‹ç»“æœ
    print("åŠ è½½åŸºçº¿é¢„æµ‹ç»“æœ...")
    baseline_df = pd.read_csv('data/NPORS_2024_for_public_release_basic_prompting.csv')
    
    # åˆå¹¶æ•°æ® (åŸºäºRESPID)
    print("åˆå¹¶æ•°æ®...")
    merged_df = finetuned_df.merge(
        baseline_df[['RESPID', 'ECON1MOD_LLM', 'UNITY_LLM', 'GPT1_LLM', 'MOREGUNIMPACT_LLM', 'GAMBLERESTR_LLM']], 
        on='RESPID', 
        how='inner'
    )
    
    print(f"åˆå¹¶åæ•°æ®: {len(merged_df)} æ¡è®°å½•")
    
    # é—®é¢˜å®šä¹‰
    questions = {
        'ECON1MOD': "How would you rate the economic conditions in your community today?",
        'UNITY': "Which statement comes closer to your own view about American values?",
        'GPT1': "Have you heard of ChatGPT?",
        'MOREGUNIMPACT': "If more Americans owned guns, do you think there would be...",
        'GAMBLERESTR': "How much government regulation of gambling do you favor?"
    }
    
    results = {}
    
    print("\n" + "="*80)
    print("å¾®è°ƒæ¨¡å‹ vs åŸºçº¿æ¨¡å‹å¯¹æ¯”åˆ†æ")
    print("="*80)
    
    for question_id in questions.keys():
        baseline_col = f'{question_id}_LLM'
        finetuned_col = f'{question_id}_FINETUNED'
        actual_col = question_id
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_mask = (
            merged_df[actual_col].notna() & 
            (merged_df[actual_col] != 99.0) &
            merged_df[baseline_col].notna() &
            merged_df[finetuned_col].notna()
        )
        
        if valid_mask.sum() == 0:
            print(f"\nâŒ {question_id}: æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            continue
        
        actual = merged_df.loc[valid_mask, actual_col].astype(int)
        baseline = merged_df.loc[valid_mask, baseline_col].astype(int) 
        finetuned = merged_df.loc[valid_mask, finetuned_col].astype(int)
        
        # è®¡ç®—å‡†ç¡®ç‡
        baseline_accuracy = (actual == baseline).mean()
        finetuned_accuracy = (actual == finetuned).mean()
        accuracy_improvement = finetuned_accuracy - baseline_accuracy
        
        # è®¡ç®—å„é€‰é¡¹çš„åˆ†å¸ƒ
        def get_distribution(values):
            return pd.Series(values).value_counts(normalize=True).sort_index()
        
        actual_dist = get_distribution(actual)
        baseline_dist = get_distribution(baseline)
        finetuned_dist = get_distribution(finetuned)
        
        # è®¡ç®—MAE (å¹³å‡ç»å¯¹è¯¯å·®)
        baseline_mae = np.mean(np.abs(actual - baseline))
        finetuned_mae = np.mean(np.abs(actual - finetuned))
        
        print(f"\nğŸ“Š {question_id}")
        print(f"   é—®é¢˜: {questions[question_id]}")
        print(f"   æ ·æœ¬æ•°: {len(actual)}")
        print(f"   åŸºçº¿å‡†ç¡®ç‡: {baseline_accuracy:.3f}")
        print(f"   å¾®è°ƒå‡†ç¡®ç‡: {finetuned_accuracy:.3f}")
        print(f"   å‡†ç¡®ç‡æå‡: {accuracy_improvement:+.3f} ({accuracy_improvement*100:+.1f}%)")
        print(f"   åŸºçº¿MAE: {baseline_mae:.3f}")
        print(f"   å¾®è°ƒMAE: {finetuned_mae:.3f}")
        
        # æ˜¾ç¤ºä¸€äº›å…·ä½“é¢„æµ‹å¯¹æ¯”
        print(f"   å…·ä½“å¯¹æ¯”ç¤ºä¾‹ (å®é™…|åŸºçº¿|å¾®è°ƒ):")
        sample_indices = actual.index[:5]  # æ˜¾ç¤ºå‰5ä¸ª
        for idx in sample_indices:
            a = actual.loc[idx]
            b = baseline.loc[idx] 
            f = finetuned.loc[idx]
            status_b = "âœ…" if a == b else "âŒ"
            status_f = "âœ…" if a == f else "âŒ"
            print(f"     {a}|{b}{status_b}|{f}{status_f}")
        
        if accuracy_improvement > 0.05:
            print("   ğŸ‰ å¾®è°ƒæ˜¾è‘—æå‡!")
        elif accuracy_improvement > 0:
            print("   âœ… å¾®è°ƒæœ‰æ‰€æå‡")
        elif accuracy_improvement < -0.05:
            print("   âš ï¸ å¾®è°ƒæ˜¾è‘—ä¸‹é™")
        else:
            print("   â– å˜åŒ–ä¸å¤§")
        
        results[question_id] = {
            'sample_size': len(actual),
            'baseline_accuracy': baseline_accuracy,
            'finetuned_accuracy': finetuned_accuracy,
            'accuracy_improvement': accuracy_improvement,
            'baseline_mae': baseline_mae,
            'finetuned_mae': finetuned_mae
        }
    
    # æ€»ä½“ç»Ÿè®¡
    if results:
        avg_baseline_acc = np.mean([r['baseline_accuracy'] for r in results.values()])
        avg_finetuned_acc = np.mean([r['finetuned_accuracy'] for r in results.values()])
        avg_improvement = avg_finetuned_acc - avg_baseline_acc
        
        print(f"\nğŸ¯ æ€»ä½“è¡¨ç°:")
        print(f"   å¹³å‡åŸºçº¿å‡†ç¡®ç‡: {avg_baseline_acc:.3f}")
        print(f"   å¹³å‡å¾®è°ƒå‡†ç¡®ç‡: {avg_finetuned_acc:.3f}")
        print(f"   å¹³å‡å‡†ç¡®ç‡æå‡: {avg_improvement:+.3f} ({avg_improvement*100:+.1f}%)")
        
        if avg_improvement > 0.03:
            print("   ğŸ‰ å¾®è°ƒå¸¦æ¥äº†æ˜¾è‘—æå‡!")
        elif avg_improvement > 0:
            print("   âœ… å¾®è°ƒæœ‰ç§¯ææ•ˆæœ")
        else:
            print("   âŒ å¾®è°ƒæ•ˆæœä¸æ˜æ˜¾")
    
    # ä¿å­˜åˆ†æç»“æœ
    with open('comparison_analysis_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nåˆ†æç»“æœå·²ä¿å­˜åˆ°: comparison_analysis_results.json")
    
    return results

if __name__ == "__main__":
    merge_and_analyze_results()