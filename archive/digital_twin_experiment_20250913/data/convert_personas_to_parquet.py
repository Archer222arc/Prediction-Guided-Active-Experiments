#!/usr/bin/env python3
"""
å°† personas_for_prediction.json è½¬æ¢ä¸º parquet æ ¼å¼
æé«˜è¯»å–æ•ˆç‡ï¼Œå‡å°‘æ–‡ä»¶å¤§å°
"""

import json
import pandas as pd
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def convert_personas_to_parquet():
    """å°† personas_for_prediction.json è½¬æ¢ä¸º parquet æ ¼å¼"""
    
    data_dir = Path("data")
    json_file = data_dir / "personas_for_prediction.json"
    parquet_file = data_dir / "personas_for_prediction.parquet"
    
    logger.info("å¼€å§‹è½¬æ¢ personas_for_prediction.json åˆ° parquet æ ¼å¼...")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not json_file.exists():
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return False
    
    try:
        # è¯»å–JSONæ–‡ä»¶
        logger.info(f"è¯»å–JSONæ–‡ä»¶: {json_file}")
        with open(json_file, 'r', encoding='utf-8') as f:
            personas_dict = json.load(f)
        
        logger.info(f"JSONæ•°æ®: {len(personas_dict)} ä¸ªpersonas")
        
        # è½¬æ¢ä¸ºDataFrame
        logger.info("è½¬æ¢ä¸ºDataFrameæ ¼å¼...")
        rows = []
        for persona_id, persona_text in personas_dict.items():
            # æå–pid
            if persona_id.startswith('pid_'):
                pid = int(persona_id.split('_')[1])
            else:
                logger.warning(f"æ— æ³•è§£æpersona_id: {persona_id}")
                continue
                
            rows.append({
                'pid': pid,
                'persona_id': persona_id,
                'persona_text': persona_text
            })
        
        df = pd.DataFrame(rows)
        
        # æŒ‰pidæ’åº
        df = df.sort_values('pid').reset_index(drop=True)
        
        logger.info(f"DataFrame: {len(df)} è¡Œ, åˆ—: {list(df.columns)}")
        
        # ä¿å­˜ä¸ºparquet
        logger.info(f"ä¿å­˜ä¸ºparquetæ ¼å¼: {parquet_file}")
        df.to_parquet(parquet_file, index=False)
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        json_size_mb = json_file.stat().st_size / (1024 * 1024)
        parquet_size_mb = parquet_file.stat().st_size / (1024 * 1024)
        
        logger.info(f"æ–‡ä»¶å¤§å°å¯¹æ¯”:")
        logger.info(f"  JSON: {json_size_mb:.2f} MB")
        logger.info(f"  Parquet: {parquet_size_mb:.2f} MB")
        logger.info(f"  å‹ç¼©ç‡: {(1 - parquet_size_mb/json_size_mb)*100:.1f}%")
        
        # éªŒè¯æ•°æ®
        logger.info("éªŒè¯è½¬æ¢åçš„æ•°æ®...")
        test_df = pd.read_parquet(parquet_file)
        
        if len(test_df) == len(df) and test_df['pid'].nunique() == len(personas_dict):
            logger.info("âœ… æ•°æ®éªŒè¯é€šè¿‡")
            
            # æ˜¾ç¤ºæ ·æœ¬
            logger.info(f"æ•°æ®æ ·æœ¬ (å‰3è¡Œ):")
            for i in range(min(3, len(test_df))):
                row = test_df.iloc[i]
                text_preview = row['persona_text'][:100] + "..." if len(row['persona_text']) > 100 else row['persona_text']
                logger.info(f"  PID {row['pid']}: {text_preview}")
            
            logger.info(f"âœ… è½¬æ¢æˆåŠŸå®Œæˆ!")
            return True
        else:
            logger.error("âŒ æ•°æ®éªŒè¯å¤±è´¥")
            return False
        
    except Exception as e:
        logger.error(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return False

def load_personas_from_parquet():
    """ä»parquetæ–‡ä»¶åŠ è½½personasæ•°æ®ï¼ˆæ¼”ç¤ºç”¨æ³•ï¼‰"""
    
    data_dir = Path("data")
    parquet_file = data_dir / "personas_for_prediction.parquet"
    
    if not parquet_file.exists():
        logger.error(f"âŒ Parquetæ–‡ä»¶ä¸å­˜åœ¨: {parquet_file}")
        return None
    
    try:
        logger.info("ä»parquetæ–‡ä»¶åŠ è½½personas...")
        df = pd.read_parquet(parquet_file)
        
        # è½¬æ¢å›å­—å…¸æ ¼å¼ï¼ˆä¸åŸJSONç›¸åŒï¼‰
        personas_dict = {}
        for _, row in df.iterrows():
            personas_dict[row['persona_id']] = row['persona_text']
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(personas_dict)} ä¸ªpersonas")
        return personas_dict
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--test-load":
        # æµ‹è¯•åŠ è½½parquetæ–‡ä»¶
        personas = load_personas_from_parquet()
        if personas:
            print(f"âœ… æˆåŠŸä»parquetåŠ è½½ {len(personas)} ä¸ªpersonas")
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬
            first_key = list(personas.keys())[0]
            first_text = personas[first_key][:200] + "..." if len(personas[first_key]) > 200 else personas[first_key]
            print(f"æ ·æœ¬ {first_key}: {first_text}")
        else:
            print("âŒ åŠ è½½å¤±è´¥")
        return
    
    # æ‰§è¡Œè½¬æ¢
    logger.info("ğŸš€ å¼€å§‹è½¬æ¢personasæ•°æ®åˆ°parquetæ ¼å¼...")
    success = convert_personas_to_parquet()
    
    if success:
        print("\n" + "="*60)
        print("ğŸ‰ Personasæ•°æ®è½¬æ¢å®Œæˆ!")
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶: data/personas_for_prediction.parquet")
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   import pandas as pd")
        print("   df = pd.read_parquet('data/personas_for_prediction.parquet')")
        print("="*60)
        print("\næµ‹è¯•åŠ è½½: python convert_personas_to_parquet.py --test-load")
    else:
        print("âŒ è½¬æ¢å¤±è´¥")

if __name__ == "__main__":
    main()