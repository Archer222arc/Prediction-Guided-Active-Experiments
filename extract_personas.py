#!/usr/bin/env python3
"""
å¯¼å‡ºä¸ 2058 ä¸ªå—è¯•è€…ä¸€ä¸€å¯¹åº”çš„ persona æ•°æ®
åŸºäºæä¾›çš„å‚è€ƒä»£ç ï¼Œä¿å­˜åˆ° data/ ç›®å½•
"""

from datasets import load_dataset
import pandas as pd
import json
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def extract_full_personas():
    """æå–å®Œæ•´çš„personaæ•°æ®å¹¶ä¿å­˜åˆ°dataç›®å½•"""
    
    # ç¡®ä¿dataç›®å½•å­˜åœ¨
    data_dir = Path("data")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info("ä»Hugging FaceåŠ è½½full_personaæ•°æ®...")
    
    try:
        # è½½å…¥"æƒå¨ persona"é…ç½®ï¼ˆä¸æ‰€æœ‰ pid ä¸€ä¸€å¯¹åº”ï¼‰
        ds = load_dataset("LLM-Digital-Twin/Twin-2K-500", "full_persona")["data"]
        df = ds.to_pandas()
        
        # åŸºæœ¬å®Œæ•´æ€§æ ¡éªŒ
        n_total = len(df)
        n_pid = df["pid"].nunique()
        logger.info(f"æ€»æ•°æ®: {n_total} è¡Œ, å”¯ä¸€pid: {n_pid}")
        
        if n_total != n_pid:
            logger.warning("âš ï¸ å­˜åœ¨é‡å¤ pidï¼Œè¯·æ£€æŸ¥ä¸Šæ¸¸æ•°æ®")
        
        if n_total != 2058:
            logger.info(f"â„¹ï¸ å½“å‰æ ·æœ¬é‡ä¸º {n_total}ï¼ˆä¸æ˜¯2058ï¼‰ï¼Œä»¥å®é™…å€¼ä¸ºå‡†")
        
        # å¯¼å‡ºä¸‰ç§å¸¸ç”¨å½¢å¼
        logger.info("å¯¼å‡ºpersonaæ•°æ®åˆ°dataç›®å½•...")
        
        # 1. Persona Summary (æœ€å¸¸ç”¨äºLLMé¢„æµ‹)
        summary_df = df[["pid", "persona_summary"]].copy()
        summary_df.to_csv(data_dir / "persona_summary.csv", index=False)
        logger.info(f"âœ… ä¿å­˜ persona_summary.csv: {len(summary_df)} æ¡è®°å½•")
        
        # 2. Persona Text (è¯¦ç»†æ–‡æœ¬)
        text_df = df[["pid", "persona_text"]].copy()
        text_df.to_csv(data_dir / "persona_text.csv", index=False)
        logger.info(f"âœ… ä¿å­˜ persona_text.csv: {len(text_df)} æ¡è®°å½•")
        
        # 3. Persona JSON (ç»“æ„åŒ–æ•°æ®)
        json_df = df[["pid", "persona_json"]].copy()
        json_df.to_csv(data_dir / "persona_json.csv", index=False)
        logger.info(f"âœ… ä¿å­˜ persona_json.csv: {len(json_df)} æ¡è®°å½•")
        
        # 4. å®Œæ•´æ•°æ® (parquetæ ¼å¼ï¼Œé«˜æ•ˆè¯»å–)
        df.to_parquet(data_dir / "full_personas.parquet", index=False)
        logger.info(f"âœ… ä¿å­˜ full_personas.parquet: å®Œæ•´æ•°æ®")
        
        # 5. ä¸ºé¢„æµ‹ç³»ç»Ÿå‡†å¤‡çš„personaså­—å…¸ (JSONæ ¼å¼)
        personas_dict = {}
        for _, row in df.iterrows():
            pid = row['pid']
            # ä¼˜å…ˆä½¿ç”¨ persona_summaryï¼Œå›é€€åˆ° persona_text
            persona_text = row.get('persona_summary') or row.get('persona_text', '')
            personas_dict[f"pid_{pid}"] = persona_text
        
        with open(data_dir / "personas_for_prediction.json", 'w', encoding='utf-8') as f:
            json.dump(personas_dict, f, indent=2, ensure_ascii=False)
        logger.info(f"âœ… ä¿å­˜ personas_for_prediction.json: {len(personas_dict)} ä¸ªpersonas")
        
        # 6. éªŒè¯æ–‡ä»¶
        logger.info("\nğŸ“‹ æ–‡ä»¶éªŒè¯:")
        for file_path in [
            "persona_summary.csv",
            "persona_text.csv", 
            "persona_json.csv",
            "full_personas.parquet",
            "personas_for_prediction.json"
        ]:
            full_path = data_dir / file_path
            if full_path.exists():
                size_mb = full_path.stat().st_size / (1024 * 1024)
                logger.info(f"  {file_path}: {size_mb:.2f} MB")
            else:
                logger.warning(f"  âŒ {file_path}: æ–‡ä»¶æœªç”Ÿæˆ")
        
        # 7. æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        logger.info(f"\nğŸ“Š æ•°æ®é¢„è§ˆ (å‰3ä¸ªpersonas):")
        for i in range(min(3, len(df))):
            pid = df.iloc[i]['pid']
            summary = df.iloc[i].get('persona_summary', '')[:100] + "..."
            logger.info(f"  PID {pid}: {summary}")
        
        logger.info(f"\nğŸ‰ Personaæ•°æ®æå–å®Œæˆ!")
        logger.info(f"æ€»è®¡: {len(df)} ä¸ªpersonas")
        logger.info(f"ä¿å­˜ç›®å½•: {data_dir.absolute()}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æå–personaæ•°æ®å¤±è´¥: {e}")
        return False

def verify_personas_data():
    """éªŒè¯å·²ä¿å­˜çš„personaæ•°æ®"""
    
    data_dir = Path("data")
    
    logger.info("éªŒè¯ä¿å­˜çš„personaæ•°æ®...")
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files = [
        "persona_summary.csv",
        "personas_for_prediction.json"
    ]
    
    for file_name in required_files:
        file_path = data_dir / file_name
        if not file_path.exists():
            logger.error(f"âŒ ç¼ºå°‘æ–‡ä»¶: {file_name}")
            return False
        else:
            logger.info(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_name}")
    
    # éªŒè¯æ•°æ®å†…å®¹
    try:
        # æ£€æŸ¥CSV
        summary_df = pd.read_csv(data_dir / "persona_summary.csv")
        logger.info(f"persona_summary.csv: {len(summary_df)} è¡Œ, åˆ—: {list(summary_df.columns)}")
        
        # æ£€æŸ¥JSON
        with open(data_dir / "personas_for_prediction.json", 'r', encoding='utf-8') as f:
            personas_dict = json.load(f)
        logger.info(f"personas_for_prediction.json: {len(personas_dict)} ä¸ªpersonas")
        
        # æ£€æŸ¥pidå¯¹åº”å…³ç³»
        csv_pids = set(summary_df['pid'])
        json_pids = set(int(k.split('_')[1]) for k in personas_dict.keys() if k.startswith('pid_'))
        
        if csv_pids == json_pids:
            logger.info("âœ… CSVå’ŒJSONä¸­çš„PIDå®Œå…¨å¯¹åº”")
        else:
            logger.warning(f"âš ï¸ PIDä¸å®Œå…¨å¯¹åº”: CSV={len(csv_pids)}, JSON={len(json_pids)}")
        
        logger.info("âœ… æ•°æ®éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--verify":
        # ä»…éªŒè¯ç°æœ‰æ•°æ®
        success = verify_personas_data()
        if success:
            print("âœ… Personaæ•°æ®éªŒè¯é€šè¿‡")
        else:
            print("âŒ Personaæ•°æ®éªŒè¯å¤±è´¥")
        return
    
    # æå–å¹¶ä¿å­˜æ•°æ®
    logger.info("ğŸš€ å¼€å§‹æå–personaæ•°æ®...")
    success = extract_full_personas()
    
    if success:
        # éªŒè¯ä¿å­˜çš„æ•°æ®
        logger.info("\nğŸ” éªŒè¯ä¿å­˜çš„æ•°æ®...")
        verify_success = verify_personas_data()
        
        if verify_success:
            print("\n" + "="*60)
            print("ğŸ‰ Personaæ•°æ®æå–å’ŒéªŒè¯å®Œæˆ!")
            print("ğŸ“ æ•°æ®ä¿å­˜ä½ç½®: ./data/")
            print("ğŸ“ ä¸»è¦æ–‡ä»¶:")
            print("  - persona_summary.csv (ç”¨äºLLMé¢„æµ‹)")
            print("  - personas_for_prediction.json (é¢„æµ‹ç³»ç»Ÿæ ¼å¼)")
            print("  - full_personas.parquet (å®Œæ•´æ•°æ®)")
            print("="*60)
            print("\nä¸‹ä¸€æ­¥: ä½¿ç”¨è¿™äº›personaæ•°æ®è¿›è¡Œé¢„æµ‹éªŒè¯")
        else:
            print("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶")
    else:
        print("âŒ Personaæ•°æ®æå–å¤±è´¥")

if __name__ == "__main__":
    main()